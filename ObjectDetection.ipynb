{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ObjectDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDVvCjU9ukqFF/UpbkF2S8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anannya233/basic-study/blob/master/ObjectDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2SWmDuMD3ma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6bbff6b-da02-49db-ea8a-1d592ea37b71"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGGRtczZtv24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "819ac5d3-41fd-4167-a66b-5dce439312a1"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9800113aa648>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqa5TD6HE4cj"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/contents/gdrive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nGl3_SFFP40"
      },
      "source": [
        "%cd \"/contents/gdrive/My Drive/Tensorflow\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGU8T-zeFQIN"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cad2-GTkBXZ",
        "outputId": "37316d36-9a2a-40d0-946a-2b3469ad70d6"
      },
      "source": [
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\r\n",
        "!pip install Cython"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "python-tk is already the newest version (2.7.17-1~18.04).\n",
            "The following additional packages will be installed:\n",
            "  python-bs4 python-chardet python-html5lib python-olefile\n",
            "  python-pkg-resources python-six python-webencodings\n",
            "Suggested packages:\n",
            "  python-genshi python-lxml-dbg python-lxml-doc python-pil-doc python-pil-dbg\n",
            "  python-setuptools\n",
            "The following NEW packages will be installed:\n",
            "  python-bs4 python-chardet python-html5lib python-lxml python-olefile\n",
            "  python-pil python-pkg-resources python-six python-webencodings\n",
            "0 upgraded, 9 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 1,615 kB of archives.\n",
            "After this operation, 8,907 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-bs4 all 4.6.0-1 [67.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-chardet all 3.0.4-1 [80.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-webencodings all 0.5-2 [10.3 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-html5lib all 0.999999999-1 [83.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-lxml amd64 4.2.1-1ubuntu0.3 [899 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-olefile all 0.45.1-1 [33.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-pil amd64 5.1.0-1ubuntu0.4 [301 kB]\n",
            "Fetched 1,615 kB in 2s (1,056 kB/s)\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 160975 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.4_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.4) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.4) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (0.29.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd_y1_5jFQRY"
      },
      "source": [
        "%cd '/content/gdrive/MyDrive/TensorFlow/models' \r\n",
        "!git checkout -f e04dafd04d69053d3733bb91d47d0d95bc2c8199"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ergZlJFFgLg"
      },
      "source": [
        "!apt-get install protobuf-compiler python-lxml python-pil\r\n",
        "!pip install Cython pandas tf-slim lvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDf_msPAFgaB"
      },
      "source": [
        "#cd into 'TensorFlow/models/research'\r\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/models/research/'\r\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyTlMBW4ZuC5"
      },
      "source": [
        "import os\r\n",
        "import sys\r\n",
        "os.environ['PYTHONPATH']+=\":/content/gdrive/My Drive/TensorFlow/models\"\r\n",
        "sys.path.append(\"/content/gdrive/My Drive/TensorFlow/models/research\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtfY1KwAZuNV"
      },
      "source": [
        "!python setup.py build \r\n",
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym3xRCLbZuRP"
      },
      "source": [
        "#cd into 'TensorFlow/models/research/object_detection/builders/'\r\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/models/research/object_detection/builders/'\r\n",
        "!python model_builder_tf2_test.py\r\n",
        "from object_detection.utils import label_map_util\r\n",
        "from object_detection.utils import visualization_utils as viz_utils\r\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6M2jrJKZuVh"
      },
      "source": [
        "#cd into preprocessing directory\r\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/scripts/preprocessing'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQI1KrNJZuY_"
      },
      "source": [
        "\r\n",
        "#run the cell to generate test.record and train.record\r\n",
        "!python generate_tfrecord.py -x '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/images/train' -l '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt' -o '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/train.record'\r\n",
        "!python generate_tfrecord.py -x '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/images/test' -l '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt' -o '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/test.record'\r\n",
        "\r\n",
        "# !python generate_tfrecord.py -x '[path_to_train_folder]' -l '[path_to_annotations_folder]/label_map.pbtxt' -o '[path_to_annotations_folder]/train.record'\r\n",
        "# !python generate_tfrecord.py -x '[path_to_test_folder]' -l '[path_to_annotations_folder]/label_map.pbtxt' -o '[path_to_annotations_folder]/test.record'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4TAQAaUZub9"
      },
      "source": [
        "#cd into training_demo\r\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/workspace/training_demo'\r\n",
        "#start the Tensorboard\r\n",
        "%load_ext tensorboard\r\n",
        "%tensorboard --logdir=models/my_ssd_resnet50_v1_fpn\r\n",
        "\r\n",
        "# %load_ext tensorboard\r\n",
        "# %tensorboard --logdir=models/[name_of_pre-trained-model_you_downloaded]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoBprT0hmCmt"
      },
      "source": [
        "#optional\r\n",
        "#code to check how much session time is remaining \r\n",
        "\r\n",
        "import time,psutil\r\n",
        "uptime=time.time()-psutil.boot_time()\r\n",
        "remaintime=(12*60*60)-uptime\r\n",
        "print(remaintime/(60*60))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l71lhV-mCz8"
      },
      "source": [
        "#Step 15- Train the model.\r\n",
        "#run the cell to start model training \r\n",
        "!python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config\r\n",
        "# !python model_main_tf2.py --model_dir=models/[name_of_pre-trained-model_you_downloaded] --pipeline_config_path=models/[name_of_pre-trained-model_you_downloaded]/pipeline.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_GhR1OYmKiI"
      },
      "source": [
        "#Step 16- Export the Trained Model.\r\n",
        "#run the cell to start model training \r\n",
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path ./models/my_ssd_resnet50_v1_fpn/pipeline.config --trained_checkpoint_dir ./models/my_ssd_resnet50_v1_fpn/ --output_directory ./exported-models/my_model\r\n",
        "# !python exporter_main_v2.py --input_type image_tensor --pipeline_config_path ./models/[name_of_pre-trained-model you downloaded]/pipeline.config --trained_checkpoint_dir ./models/[name_of_pre-trained-model_you_downloaded]/ --output_directory ./exported-models/my_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IXB2inEmKlv"
      },
      "source": [
        "#Step 17- Test the Model.\r\n",
        "\r\n",
        "#Loading the saved_model\r\n",
        "import tensorflow as tf\r\n",
        "import time\r\n",
        "from object_detection.utils import label_map_util\r\n",
        "from object_detection.utils import visualization_utils as viz_utils\r\n",
        "\r\n",
        "PATH_TO_SAVED_MODEL=\"/content/gdrive/My Drive/TensorFlow/workspace/training_demo/exported-models/my_model/saved_model\"\r\n",
        "\r\n",
        "print('Loading model...', end='')\r\n",
        "\r\n",
        "# Load saved model and build the detection function\r\n",
        "detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\r\n",
        "\r\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_QrjB5hmKpb"
      },
      "source": [
        "#Step 18- Testing the Model.\r\n",
        "\r\n",
        "#Loading the label_map\r\n",
        "category_index=label_map_util.create_category_index_from_labelmap(\"/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt\",use_display_name=True)\r\n",
        "\r\n",
        "#category_index=label_map_util.create_category_index_from_labelmap([path_to_label_map],use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UURD_H_c5grh"
      },
      "source": [
        "#Step 19- Testing the Model.\n",
        "\n",
        "#Loading the image\n",
        "img=['/content/img1.jpg','/content/img2.jpg']\n",
        "print(img)\n",
        "\n",
        "#list containing paths of all the images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAvu42semKwq"
      },
      "source": [
        "#Step 20- Running the Inference.\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\r\n",
        "\r\n",
        "def load_image_into_numpy_array(path):\r\n",
        "    \"\"\"Load an image from file into a numpy array.\r\n",
        "\r\n",
        "    Puts image into numpy array to feed into tensorflow graph.\r\n",
        "    Note that by convention we put it into a numpy array with shape\r\n",
        "    (height, width, channels), where channels=3 for RGB.\r\n",
        "\r\n",
        "    Args:\r\n",
        "      path: the file path to the image\r\n",
        "\r\n",
        "    Returns:\r\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\r\n",
        "    \"\"\"\r\n",
        "    return np.array(Image.open(path))\r\n",
        "\r\n",
        "for image_path in img:\r\n",
        "\r\n",
        "    print('Running inference for {}... '.format(image_path), end='')\r\n",
        "    image_np=load_image_into_numpy_array(image_path)\r\n",
        "\r\n",
        "    # Things to try:\r\n",
        "    # Flip horizontally\r\n",
        "    # image_np = np.fliplr(image_np).copy()\r\n",
        "    # Convert image to grayscale\r\n",
        "    # image_np = np.tile(\r\n",
        "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\r\n",
        "\r\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\r\n",
        "    input_tensor=tf.convert_to_tensor(image_np)\r\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\r\n",
        "    input_tensor=input_tensor[tf.newaxis, ...]\r\n",
        "\r\n",
        "    # input_tensor = np.expand_dims(image_np, 0)\r\n",
        "    detections=detect_fn(input_tensor)\r\n",
        "\r\n",
        "    # All outputs are batches tensors.\r\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\r\n",
        "    # We're only interested in the first num_detections.\r\n",
        "    num_detections=int(detections.pop('num_detections'))\r\n",
        "    detections={key:value[0,:num_detections].numpy()\r\n",
        "                   for key,value in detections.items()}\r\n",
        "    detections['num_detections']=num_detections\r\n",
        "\r\n",
        "    # detection_classes should be ints.\r\n",
        "    detections['detection_classes']=detections['detection_classes'].astype(np.int64)\r\n",
        "\r\n",
        "    image_np_with_detections=image_np.copy()\r\n",
        "\r\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\r\n",
        "          image_np_with_detections,\r\n",
        "          detections['detection_boxes'],\r\n",
        "          detections['detection_classes'],\r\n",
        "          detections['detection_scores'],\r\n",
        "          category_index,\r\n",
        "          use_normalized_coordinates=True,\r\n",
        "          max_boxes_to_draw=1,     #max number of bounding boxes in the image\r\n",
        "          min_score_thresh=.3,      #min prediction threshold\r\n",
        "          agnostic_mode=False)\r\n",
        "    %matplotlib inline\r\n",
        "    plt.figure()\r\n",
        "    plt.imshow(image_np_with_detections)\r\n",
        "    print('Done')\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP7vKcUgmxwD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYPbm3xbmx3v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bHq5TWjmC4q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}